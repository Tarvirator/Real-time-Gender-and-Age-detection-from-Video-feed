{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"7usTYKr4ycVu"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JSzGamG8ysYk"},"outputs":[],"source":["#install this library for face detection model\n","!pip install retina_face==0.0.13 --quiet"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J9DONi7GypfZ"},"outputs":[],"source":["#import the libraries\n","from tensorflow.keras.models import load_model\n","import numpy as np\n","import cv2\n","from retinaface import RetinaFace\n","# from google.colab.patches import cv2_imshow #colab patch for cv2\n","from tqdm import tqdm"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QGAh3HZM7clp"},"outputs":[],"source":["videopath=\"./01313031.mp4\"\n","webcam = cv2.VideoCapture(videopath)\n","# webcam=cv2.VideoCapture(0) #for webcam"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1SoGZMdw7hhB"},"outputs":[],"source":["frames=int(webcam.get(cv2.CAP_PROP_FRAME_COUNT))\n","frames"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IQMR_E4A5wAm"},"outputs":[],"source":["gen_class = ['man','woman']\n","age_class = ['1-3','4-10','11-19','20-35','36-50','51-65','65+']\n","\n","# load the gender and age pred models\n","model_age=load_model(\"./model/Age_prediction_model.h5\")\n","model_gen=load_model(\"./model/Gender_prediction_model.h5\")\n","\n","#open video feed\n","webcam = cv2.VideoCapture(videopath)\n","\n","\n","frame_width = int(webcam.get(3))\n","frame_height = int(webcam.get(4))\n","fps=webcam.get(cv2.CAP_PROP_FPS)\n","\n","#define parameters for saving the video after detection\n","fourcc = cv2.VideoWriter_fourcc(*'XVID')\n","new_my_video =new_my_video = videopath[:-4]+\"_detect_gen_age3.avi\"\n","out = cv2.VideoWriter(new_my_video, fourcc, 15, (frame_width, frame_height))\n","\n","# loop through frames\n","count=0\n","while webcam.isOpened():\n","  status, frame = webcam.read()\n","  try:\n","    #detect the facial region with retinaface\n","    obj = RetinaFace.detect_faces(frame)\n","    try:\n","      for key in obj.keys():\n","        identify = obj[key]\n","        facial_area = identify[\"facial_area\"]\n","\n","        (startX, startY) = facial_area[2]+10, facial_area[3]+10\n","        (endX, endY) = facial_area[0]-10, facial_area[1]-10\n","\n","        #draw bounding box around the face\n","        cv2.rectangle(frame, (startX,startY), (endX, endY), (0, 255, 0), 2)\n","\n","        #copy the face region\n","        face_crop = np.copy(frame[endY:startY,endX:startX])\n","\n","        face_crop = cv2.resize(face_crop, (224,224))\n","        face_crop = face_crop.astype(\"float\")\n","        face_crop=face_crop.reshape(-1,224,224,3)\n","\n","\n","        #make predictions\n","        conf_gen = model_gen.predict(face_crop,verbose=0)[0]\n","        conf_age = model_age.predict(face_crop,verbose=0)[0]\n","\n","        idx_gen = np.argmax(conf_gen)\n","        label_gen = gen_class[idx_gen]\n","\n","        idx_age = np.argmax(conf_age)\n","        label_age = age_class[idx_age]\n","\n","        #annotate on the frame\n","        label = \"{}: {}\".format(label_gen, label_age)\n","\n","        Y = startY - 10 if startY - 10 > 10 else startY + 10\n","\n","        cv2.putText(frame, label, (startX, Y),  cv2.FONT_HERSHEY_SIMPLEX,\n","                    0.5, (0, 255, 0), 2)\n","    except:\n","      continue\n","    out.write(frame) #save the frame to the video\n","  except:\n","    continue\n","\n","  count+=1\n","  print(\"{}/{} frames done\".format(count,frames))\n","  if (count)==3000:\n","    break\n","  # cv2_imshow(frame)\n","\n","  # press \"Q\" to stop\n","  if cv2.waitKey(1) & 0xFF == ord('q'):\n","      break\n","\n","# release resources\n","webcam.release()\n","cv2.destroyAllWindows()"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
